{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 파이썬을 이용한 웹 크롤링 기본 (requests 패키지와  bs4 패키지)\n",
    "- requests 패키지 : 웹페이지에 접속해서 접속한 웹페이지를 객체로 가져올 수 있도록 해준다.\n",
    " - get : 사용자가 입력한 주소의 html 페이지를 가져온다.\n",
    "- bs4 패키지 : html 태그를 파싱(해석)해서 필요한 데이타를 추출할 수 있도록 해준다.\n",
    " - BeautifulSoup : bs4 패키지 내의 클래스로 html 문서를 파싱 가능한 객체로 만들어준다\n",
    "   - find : 찾고 싶은 태그중 가장 먼저 검색되는 태그를 찾아준다. \n",
    "   - find_all : 찾고 싶은 전체 테그를 찾아준다. \n",
    "   - get_text : 해당 태그의 데이타를 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 웹페이지는 ?\n",
    "- html, css, javascript 등으로 구성된다. \n",
    "- html 언어는 웹페이지를 만드는 기본 언어로 <태그> 보여줄 내용 </태그> 형식으로 되어 있음\n",
    "- 알고있어야 할 html 기본 태그 \n",
    " - html, head, body, title, meta, h1~h6, p, br, strong, b, em, i, span, hr 등   \n",
    " - ul, ol, li, dl, dt, dd 등\n",
    " - table, thead, tbody, tr, th 등\n",
    " - img, a, div 등\n",
    "- 웹페이지에 css(글자 모양, 크기, 색깔, 정렬 등)을 적용하는 3가지 방법\n",
    " - html 태그에 일일히 style 속성을 지정하는 방법(inline 방식)\n",
    " - head 태그 안에 style 태그를 만들고, 그 안에 style 관련 코드를 쓰는 방식(내부 style 시트 방식)\n",
    " - 별도의 화일에 style을 만들어 놓은 후 이용하는 방식(외부 style 시트 방식)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 웹페이지에서 원하는 데이타를 크롤링 하기 위해서는  ?\n",
    "- requests 패키지와 BeautifulSoup 클래스를 이용하여 크롤링 코드를 작성한다. \n",
    "- 크롤링할 데이타의 html 태그를 확인한다.\n",
    "- 크롤링 할 html 태그가 유일하면 find('태그')를 호출한다.\n",
    "- 동일한 html 태그가 여러개 있을 때 그 중 하나를 선택하는 경우에는 \n",
    " - find('태그', class_='스타일이름') \n",
    " - find('태그', '스타일이름')   # 위에서 class_ 를 생략할 수 있다 \n",
    " - find('태그', attrs={'속성':'값', '속성':'값', ....}) \n",
    " - find(id='이름')\n",
    "- 동일한 html 태그가 여러개 있을 때 모두를 다 선택해야 하는 경우에는 \n",
    " - find_all('태그') 함수를 이용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HTML 태그만을 이용한  크롤링 해보기 \n",
    "- 문자열 변수 page에 아래와 같은 html 문서의 내용이 저장되어 있다.\n",
    "- HTML 태그와 속성중 title, h1, p, id, align 을 이용하여 크롤링 해보시오.\n",
    "- h1, p 태그처럼 여러번 반복되어 나와 있는 태그의 경우 모든 데이타를 다 크롤링 해보시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 웹 크롤링 기술 \n",
      " [1] 파이썬 문법 \n",
      " [5] 프로젝트 하기 \n",
      " [5] Selenium 패키지 사용법 익히기 \n",
      "2\n",
      " [1] 파이썬 문법 \n",
      " [5] 프로젝트 하기 \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = \"\"\"     \n",
    "<html> \n",
    "    <head>  \n",
    "         <meta charset=\"utf-8\">\t\n",
    "         <title> 웹 크롤링 기술 </title>\n",
    "    </head>    \n",
    "    <body>\n",
    "        <h1> [1] 파이썬 문법 </h1> \n",
    "        <h2> [2] html 사용법 </h2> \n",
    "        <h3> [3] BeautifulSoap 클래스 사용법 </h3>         \n",
    "        <p id='body1' align='left'> [4] Open API 사용법 익히기 </p> \n",
    "        <p id='body2' align='center'> [5] Selenium 패키지 사용법 익히기 </p> \n",
    "        <p id='body3' align='right'> [6] 웹크롤러 만드는 법 </p> \n",
    "        <h1 id='body4'> [5] 프로젝트 하기 </h1> \n",
    "    </body> \n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "data_title = soup.find('title')\n",
    "print(data_title.get_text()) \n",
    "\n",
    "data_h1 = soup.find('h1')\n",
    "print(data_h1.get_text())\n",
    "\n",
    "data_p = soup.find(id='body4')\n",
    "print(data_p.get_text())     \n",
    "\n",
    "data_p = soup.find('p', attrs={ 'align':'center' })\n",
    "print(data_p.get_text()) \n",
    "\n",
    "data_h1_all = soup.find_all('h1')\n",
    "print(len(data_h1_all))\n",
    "for i in data_h1_all :\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. html 코드와 css 를 이용한  크롤링 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 학번 \n",
      " 이름 \n",
      " sample test \n",
      " 20123123\n",
      " 홍길동\n",
      " 20123124\n",
      " 김철수\n",
      "\n",
      " 20123124\n",
      "\n",
      " 20123124\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title> sample test </title>\n",
    "    <meta charset=\"utf-8\">\n",
    "<!-- 내부 스타일 시트 \n",
    "    <style type=\"text/css\">\n",
    "        td {\n",
    "            font-size: 2em;\n",
    "            font-family: Gothic;\n",
    "            text-align: cener;\n",
    "            color: blue\n",
    "        }\n",
    "    </style>\n",
    "-->\n",
    "<!-- 외부 스타일 (외부 파일에 스타일을 정의한 후  href 속성에 파일 이름을 지정한다) -->\n",
    "    <link rel=\"stylesheet\" type=\"text/css\" href=\"style.css\">\n",
    "\n",
    "  </head>\n",
    "  <body>\n",
    "    <table border=1 width=\"500\">\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th> 학번 </th>\n",
    "                <th> 이름 </th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td style='text-align:right;color:red;font-size:16px'> 20123123</td>\n",
    "                <td class='normal'> 홍길동</td> \n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td class='highlight'> 20123124</td>\n",
    "                <td class='normal'> 김철수</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>   \n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "data_th = soup.find_all('th')\n",
    "for i in data_th :\n",
    "    print(i.get_text())\n",
    "    \n",
    "data_titel = soup.find('title')    \n",
    "print(data_titel.get_text())\n",
    "\n",
    "data_td = soup.find_all('td') \n",
    "for i in data_td :\n",
    "    print(i.get_text())\n",
    "\n",
    "print()\n",
    "data_td = soup.find('td',class_='highlight')\n",
    "print(data_td.get_text())\n",
    "\n",
    "print()\n",
    "data_td = soup.find('td','highlight')\n",
    "print(data_td.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 웹페이지에서 원하는 부분 크롤링 해보기\n",
    "- 크롬 브라우저를 이용하여 원하는 페이지를 검색한다\n",
    "- 마우스 오른쪽 버튼을 눌러 페이지 소스 보기를 선택한다.\n",
    "- 크롤링할 데이타의 html 태그를 확인한다.\n",
    "- requests 패키지와 BeautifulSoup 클래스를 이용하여 크롤링 코드를 작성한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 웹 페이지  크롤링  해보기 1(네이버 사전 페이지의 제목 크롤링 해보기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>네이버 사전 (NAVER dictionary)</title>\n",
      "네이버 사전 (NAVER dictionary)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://dict.naver.com/')    # 입력한 주소(https://dict.naver.com/)의 페이지 객체를 가져온다. \n",
    "soup = BeautifulSoup(page.content,'html.parser')  # 가져온 페이지 객체의 내용을 html 파서를 이용하여 파싱가능한 객체로 만들어준다\n",
    "\n",
    "data_titel = soup.find('title')\n",
    "print(data_titel)\n",
    "print(data_titel.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 웹 페이지  크롤링  해보기 2(다음 홈페이지의  IT 뉴스 헤드라인 크롤링 해보기) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<strong class=\"tit_thumb\">\n",
      "<a class=\"link_txt\" data-tiara-custom=\"contentUniqueKey=hamny-20200420151205240\" data-tiara-id=\"20200420151205240\" data-tiara-layer=\"article_main\" data-tiara-ordnum=\"1\" data-tiara-type=\"harmony\" href=\"https://news.v.daum.net/v/20200420151205240\">\"코로나19 '확찐자' 늘어..덜 걷고 더 잔다\"</a>\n",
      "</strong>\n",
      "\n",
      "\"코로나19 '확찐자' 늘어..덜 걷고 더 잔다\"\n",
      "\n",
      "[<p>최근 신종 코로나바이러스 감염증(코로나19) 영향으로 자가 격리, 외출 자제, 재택근무 등 일상생활 패턴이 바뀌면서 '확찐자', '코로나 블루' 등 신조어가 생겨나고 있다.</p>, <p>'확찐자'는 코로나19로 실내 생활 비중이 늘어나면서 급격히 살을 찐 사람을 뜻하는 신조어다.</p>, <p>핏빗은 이러한 수치는 전 세계 사람들이 코로나19 확산을 막기 위해 '사회적 거리두기' 임무를 수행하고 있다는 점을 확연히 보여준다고 분석했다.</p>, <p class=\"desc_translate txt_newsview\">Translated by <a class=\"link_kakaoi #util #translate #kakaoi_link\" href=\"https://kakao.ai/\" target=\"_blank\">kakao i</a></p>, <p dmcf-pid=\"jGWKeXyxY9\" dmcf-ptype=\"general\">(지디넷코리아=황정빈 기자)최근 신종 코로나바이러스 감염증(코로나19) 영향으로 자가 격리, 외출 자제, 재택근무 등 일상생활 패턴이 바뀌면서 '확찐자', '코로나 블루' 등 신조어가 생겨나고 있다. '확찐자'는 코로나19로 실내 생활 비중이 늘어나면서 급격히 살을 찐 사람을 뜻하는 신조어다.</p>, <p dmcf-pid=\"jOaYdIcMA2\" dmcf-ptype=\"general\">글로벌 웨어러블 브랜드 핏빗은 실제로 코로나19로 전 세계적으로 활동량이 줄어들고 수민 시간이 늘어났다는 사실이 데이터로 증명됐다고 20일 밝혔다.</p>, <p dmcf-pid=\"j7N2ut4yaw\" dmcf-ptype=\"general\">핏빗은 전 세계 3천만 명 이상의 핏빗 스마트워치 및 트래커 사용자의 활동량과 수면 데이터의 변화를 공개했다.</p>, <p class=\"link_figure\"><img alt=\"2020년 1~4월 간 전 세계 주요 도시 걸음 수 변화. (자료=핏빗)\" class=\"thumb_g_article\" dmcf-mid=\"jmaMSqE4YO\" dmcf-mtype=\"image\" height=\"320\" src=\"https://t1.daumcdn.net/news/202004/20/ZDNetKorea/20200420151316099pnnh.jpg\" width=\"640\"/></p>, <p dmcf-pid=\"joyhM6VznB\" dmcf-ptype=\"general\">핏빗이 공개한 통계에 따르면, 전 세계적으로 본격적인 자가격리가 시행된 지난달 22일 기점으로 유럽에선 걸음 수가 전년 대비 7~38% 감소한 것으로 나타났다. 특히, 강력한 도시 봉쇄 조치를 취한 스페인, 이탈리아, 포르투갈은 각 38%, 25%, 25% 감소했다. 3월 중순 고강도 사회적 거리두기를 실천한 한국도 걸음 수가 약 10% 줄었다.</p>, <p dmcf-pid=\"j3Hoc9haE0\" dmcf-ptype=\"general\">핏빗은 이러한 수치는 전 세계 사람들이 코로나19 확산을 막기 위해 '사회적 거리두기' 임무를 수행하고 있다는 점을 확연히 보여준다고 분석했다.</p>, <p dmcf-pid=\"jLZNEzF5UG\" dmcf-ptype=\"general\">또 사회적 거리두기와 자가 격리 수칙이 준수될수록 사람들은 더 많이 자고, 더 깊은 잠을 취하는 것으로 나타났다.</p>, <p class=\"link_figure\"><img alt=\"2020년 2월 9일부터 유럽 내 핏빗 사용자 수면량 변화. (자료=핏빗)\" class=\"thumb_g_article\" dmcf-mid=\"jXjVyfqSJ5\" dmcf-mtype=\"image\" height=\"426\" src=\"https://t1.daumcdn.net/news/202004/20/ZDNetKorea/20200420151316735sprt.jpg\" width=\"640\"/></p>, <p dmcf-pid=\"jpcTlHcUf7\" dmcf-ptype=\"general\">핏빗에 따르면 미국 내 핏빗 사용자의 3월 셋째 주 수면 패턴을 분석한 결과, 평소보다 최대 25분가량 수면 시간이 늘어났다.</p>, <p dmcf-pid=\"jKZeohEZWE\" dmcf-ptype=\"general\">유럽에서도 비슷한 성향을 보였다. 프랑스 파리의 경우, 학교 폐쇄와 정부 차원의 사회적 거리두기가 본격적으로 시작된 지난 3월 15일을 기점으로 수면 양이 급격히 증가했다. 이탈리아 밀라노도 지난 3월 초 전국이 봉쇄된 시점부터 수면 시간이 늘어난 것으로 파악됐다.</p>, <p dmcf-pid=\"jZ3dT0QmwM\" dmcf-ptype=\"general\">핏빗은 \"적절한 수면은 면역력 향상에 도움 되지만, 수면 시간이 더 길어졌다고 해서 건강이 보장되는 것은 아니\"라며 \"언제, 어떻게 수면하는지가 신체 항상성을 최적화하는 데 큰 영향을 미친다\"고 조언했다.</p>, <p dmcf-pid=\"ju6PaWZ2Qv\" dmcf-ptype=\"general\">이어 \"실내에서 머무르는 것을 최대한 활용해 가족과 함께, 또는 집에서 할 수 있는 쉽게 몰입할 수 있고 효과적인 운동을 찾을 것을 추천한다\"며 \"핏빗의 피트니스 개인 레슨 기능인 핏빗 코치를 이용하거나 또는 핏빗 코치 앱을 통해 운동 영상을 내려받아 맨손 체조와 스트레칭 등 간단한 운동을 할 수 있다\"고 덧붙였다.</p>, <p dmcf-pid=\"jZV7gPhVd6\" dmcf-ptype=\"general\">황정빈 기자(jungvinh@zdnet.co.kr)</p>]\n",
      "\n",
      "최근 신종 코로나바이러스 감염증(코로나19) 영향으로 자가 격리, 외출 자제, 재택근무 등 일상생활 패턴이 바뀌면서 '확찐자', '코로나 블루' 등 신조어가 생겨나고 있다.\n",
      "'확찐자'는 코로나19로 실내 생활 비중이 늘어나면서 급격히 살을 찐 사람을 뜻하는 신조어다.\n",
      "핏빗은 이러한 수치는 전 세계 사람들이 코로나19 확산을 막기 위해 '사회적 거리두기' 임무를 수행하고 있다는 점을 확연히 보여준다고 분석했다.\n",
      "None\n",
      "(지디넷코리아=황정빈 기자)최근 신종 코로나바이러스 감염증(코로나19) 영향으로 자가 격리, 외출 자제, 재택근무 등 일상생활 패턴이 바뀌면서 '확찐자', '코로나 블루' 등 신조어가 생겨나고 있다. '확찐자'는 코로나19로 실내 생활 비중이 늘어나면서 급격히 살을 찐 사람을 뜻하는 신조어다.\n",
      "글로벌 웨어러블 브랜드 핏빗은 실제로 코로나19로 전 세계적으로 활동량이 줄어들고 수민 시간이 늘어났다는 사실이 데이터로 증명됐다고 20일 밝혔다.\n",
      "핏빗은 전 세계 3천만 명 이상의 핏빗 스마트워치 및 트래커 사용자의 활동량과 수면 데이터의 변화를 공개했다.\n",
      "None\n",
      "핏빗이 공개한 통계에 따르면, 전 세계적으로 본격적인 자가격리가 시행된 지난달 22일 기점으로 유럽에선 걸음 수가 전년 대비 7~38% 감소한 것으로 나타났다. 특히, 강력한 도시 봉쇄 조치를 취한 스페인, 이탈리아, 포르투갈은 각 38%, 25%, 25% 감소했다. 3월 중순 고강도 사회적 거리두기를 실천한 한국도 걸음 수가 약 10% 줄었다.\n",
      "핏빗은 이러한 수치는 전 세계 사람들이 코로나19 확산을 막기 위해 '사회적 거리두기' 임무를 수행하고 있다는 점을 확연히 보여준다고 분석했다.\n",
      "또 사회적 거리두기와 자가 격리 수칙이 준수될수록 사람들은 더 많이 자고, 더 깊은 잠을 취하는 것으로 나타났다.\n",
      "None\n",
      "핏빗에 따르면 미국 내 핏빗 사용자의 3월 셋째 주 수면 패턴을 분석한 결과, 평소보다 최대 25분가량 수면 시간이 늘어났다.\n",
      "유럽에서도 비슷한 성향을 보였다. 프랑스 파리의 경우, 학교 폐쇄와 정부 차원의 사회적 거리두기가 본격적으로 시작된 지난 3월 15일을 기점으로 수면 양이 급격히 증가했다. 이탈리아 밀라노도 지난 3월 초 전국이 봉쇄된 시점부터 수면 시간이 늘어난 것으로 파악됐다.\n",
      "핏빗은 \"적절한 수면은 면역력 향상에 도움 되지만, 수면 시간이 더 길어졌다고 해서 건강이 보장되는 것은 아니\"라며 \"언제, 어떻게 수면하는지가 신체 항상성을 최적화하는 데 큰 영향을 미친다\"고 조언했다.\n",
      "이어 \"실내에서 머무르는 것을 최대한 활용해 가족과 함께, 또는 집에서 할 수 있는 쉽게 몰입할 수 있고 효과적인 운동을 찾을 것을 추천한다\"며 \"핏빗의 피트니스 개인 레슨 기능인 핏빗 코치를 이용하거나 또는 핏빗 코치 앱을 통해 운동 영상을 내려받아 맨손 체조와 스트레칭 등 간단한 운동을 할 수 있다\"고 덧붙였다.\n",
      "황정빈 기자(jungvinh@zdnet.co.kr)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup                  # 뉴스이기 때문에 날짜별로 실행시킬때 마다 결과가 다르게 나올 수 있다. \n",
    "\n",
    "page = requests.get('https://news.daum.net/digital')  # IT 뉴스의 헤드라인\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "\n",
    "data = soup.find('strong', class_='tit_thumb')\n",
    "print(data)\n",
    "print(data.get_text())\n",
    "\n",
    "page = requests.get('https://news.v.daum.net/v/20200420151205240')  # IT 뉴스의 헤드라인\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "# data_p = soup.find('p')\n",
    "# print(data_p.get_text())\n",
    "\n",
    "data_p = soup.find_all('p')\n",
    "print(data_p) \n",
    "\n",
    "print()\n",
    "for i in data_p :\n",
    "    print(i.get_text())\n",
    "    #print(i.text)\n",
    "    #print(i.string)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
